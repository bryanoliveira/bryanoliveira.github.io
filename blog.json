[{"html":"<p>A <a href=\"https://en.wikipedia.org/wiki/Cellular_automaton\">Cellular Automata</a> program built with C++, CUDA and OpenGL. It&#39;s built to run on a GPU but it also supports CPU-only execution (mainly for relative speedup comparisons). On the right there&#39;s an example execution of <a href=\"https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life\">Conway&#39;s Game of Life</a> on a 100x100 randomly initialized grid.</p>\n<p>The main objective of this project is to allow scaling up to a reasonably large number of cells while maintaining the code legibility and allowing for further customizations. It supports command line arguments to set up quick configs (run <code>./automata -h</code> for details) like headless mode (which is significantly faster) and initial patterns (which can be loaded from the <code>patterns</code> folder). It doesn&#39;t yet support the definition of evolution rules at runtime or lattice size inference, but I&#39;m working on that.</p>\n<p>This program can currently evolve a dense &amp; high entropy 182.25 million cell Game of Life grid (13500x13500) with rendering enabled with up to 320 generations per second on a Ryzen 7 3700X / RTX 3080 using up to 200MB RAM and 8.5GB VRAM (which is the actual scaling limiter).</p>\n<p>The ability to evolve and render such large grids allows the program to run some really interesting patterns, like evolving the Game of Life <em>within</em> the Game of Life:</p>\n<div align=\"center\">\n    <img class=\"text-img mw-75\" src=\"https://github.com/bryanoliveira/cellular-automata/raw/master/docs/zoom.gif\">\n</div>\n\n<p>In the GIF above we&#39;re running a 12300x12300 grid using Game of Life rules to evolve a pattern known as <a href=\"http://b3s23life.blogspot.com/2006_09_01_archive.html\">Meta-Toad</a>. It uses a grid of <a href=\"https://www.conwaylife.com/wiki/OTCA_metapixel\">OTCA Metapixels</a> and requires about 35 thousand generations of the underlying automaton to represent a single generation of the meta-grid. The pattern being evolved by the meta-grid is known as <a href=\"https://www.conwaylife.com/wiki/Toad\">Toad</a>:</p>\n<div align=\"center\">\n    <img class=\"text-img\" src=\"https://github.com/bryanoliveira/cellular-automata/raw/master/docs/toad.gif\" width=\"150\">\n</div>\n\n<p>This program also supports a benchmark mode (<code>-b</code> option), which outputs the total and average evolution and rendering timings to stdout. Combined with <code>benchmark.sh</code> and <code>benchmark_visualize.ipynb</code>, it is possible to plot speedups and evolution times for different lattice sizes. Currently, the GPU implementation achieves a relative speedup of more than 3000x over the single-core CPU implementation.</p>\n<div align=\"center\">\n<br/>\n<img src=\"https://raw.githubusercontent.com/bryanoliveira/cellular-automata/master/docs/speedup.png\" align=\"center\" width=\"300\">\n<img src=\"https://raw.githubusercontent.com/bryanoliveira/cellular-automata/master/docs/avg_time.png\" align=\"center\" width=\"338\">\n</div>\n<br/>\n\n<blockquote>\n<p>Speedup over serial (left) and average grid evolution time (right) for lattice sizes 32x32, 64x64, ..., 8192x8192 and 1000 generations. For these tests, initial spawn probability was set to 0.5 and rendering was disabled.</p>\n</blockquote>\n<h2 id=\"requirements\">Requirements</h2>\n<p>To run the program you&#39;ll need:</p>\n<ul>\n<li>  Debian-like linux distro (I only tested this on Ubuntu 20)</li>\n<li>OpenGL (GLEW and GLUT)<ul>\n<li>  e.g. <code>sudo apt-get install libglew2.1 freeglut3-dev</code></li>\n</ul>\n</li>\n<li>  <a href=\"https://developer.nvidia.com/cuda-downloads\">CUDA</a> (nvcc) and CUDA runtime libraries</li>\n</ul>\n<p>To build it from source you&#39;ll also need:</p>\n<ul>\n<li>g++ (C++ 17) and <em>make</em><ul>\n<li>  e.g. <code>sudo apt install build-essential</code></li>\n</ul>\n</li>\n<li>  Boost C++ Library (program_options module)</li>\n<li>  <a href=\"https://github.com/gabime/spdlog\">spdlog</a></li>\n</ul>\n<p>It is possible to run this program in a CPU-only mode, so if you don&#39;t have a CUDA-capable video card you may skip the last step. For that to work you will need to run the program with <code>./automata --cpu</code> and disable <code>*.cu</code> file compilation in the <code>Makefile</code>.</p>\n<h2 id=\"usage\">Usage</h2>\n<h3 id=\"executing-a-pre-built-binary-linux-x64--cuda-only\">Executing a pre-built binary (Linux x64 + CUDA only)</h3>\n<ul>\n<li>  Download <code>cellular-automata-linux64.zip</code> from the <a href=\"https://github.com/bryanoliveira/cellular-automata/releases\">latest release</a></li>\n<li>  Extract the executable (<code>automata</code>) and the <code>patterns</code> folder</li>\n<li>  Install OpenGL and CUDA from the requirements above</li>\n<li>  Run <code>./automata -h</code> to see all the available options</li>\n<li>  Run the program with <code>./automata --render</code>.</li>\n</ul>\n<p>If your GPU has enough VRAM (&gt;= 8 GB), you may be able to reproduce the Meta-Toad simulation above. Run <code>./automata -r -x 12300 -y 12300 -p 0 -f patterns/meta-toad.rle</code> to try it out!</p>\n<h3 id=\"building-from-source\">Building From Source</h3>\n<ul>\n<li>  Install the requirements</li>\n<li>  Clone this repository</li>\n<li>Building and executing:<ul>\n<li>  Run <code>make</code> to build and run</li>\n<li>  Run <code>make build</code> to build</li>\n<li>  Run <code>make run</code> to run with default parameters</li>\n<li>  Run <code>make clean</code> to remove generated files</li>\n<li>  Run <code>make profile</code> to run <a href=\"https://developer.nvidia.com/nsight-systems\">NVIDIA&#39;s nsys</a> profiling.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"runtime-controls\">Runtime Controls</h3>\n<ul>\n<li>Basic controls:<ul>\n<li>  <strong>space</strong> pauses/resumes the simulation;</li>\n<li>  <strong>enter/return</strong> runs a single generation;</li>\n<li>  <strong>left mouse click</strong> translates the grid relative to the max resolution</li>\n<li>  <strong>ctrl + left mouse click</strong> translates the camera relative to the world</li>\n<li>  <strong>mouse scroll</strong> zooms the grid in and out, relative to the max resolution</li>\n<li>  <strong>ctrl + mouse scroll</strong> zooms the camera, relative to the world</li>\n<li>  <strong>middle mouse click</strong> resets scale and translation</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"next-steps\">Next steps</h2>\n<p>There is still much room for improvement. This includes better memory management, use of CPU parallelism and automated tests. My next steps include (but are not limited to):</p>\n<ul>\n<li>  Addition of unit tests (in progress)</li>\n<li>  Parallel CPU implementation (in progress)</li>\n<li>  Usage of templates to abstract grid data types (e.g. cells should be represented with 1 bit instead of 8)</li>\n<li>  Usage of SM shared memory to explore data locality</li>\n<li>  Support for flexible rule definition</li>\n<li>  Support for infinite grids (e.g. storing only active cells)</li>\n<li>  Support for 3-D and N-D grids</li>\n</ul>\n<h2 id=\"references\">References</h2>\n<ul>\n<li>  What are <a href=\"https://en.wikipedia.org/wiki/Cellular_automaton\">Cellular Automata</a>?</li>\n<li>  What is <a href=\"https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life\">Conway&#39;s Game of Life</a>?</li>\n<li>  <a href=\"http://golly.sourceforge.net/\">Golly</a>: an open source cellular automata simulator that supports several Game of Life and other automata algorithms;</li>\n<li>  <a href=\"https://copy.sh/life/\">Life</a>: an open source JavaScript implementation of Game of Life that runs in the browser;</li>\n<li>  <a href=\"http://b3s23life.blogspot.com/2006_09_01_archive.html\">Conway&#39;s Life: Work in Progress</a>: where I got the initial pattern for the Meta-Toad;</li>\n<li>  <a href=\"https://blog.amandaghassaei.com/2020/05/01/the-recursive-universe/\">The Recursive Universe</a>: explores and explains how some of the meta-patterns work;</li>\n<li>  What are <a href=\"https://www.conwaylife.com/wiki/OTCA_metapixel\">OTCA Metapixels</a>?</li>\n</ul>\n<h2 id=\"bonus\">Bonus</h2>\n<div align=\"center\">\n<img class=\"text-img mw-100\" src=\"https://github.com/bryanoliveira/cellular-automata/raw/master/docs/1000x1000.gif\"/>\n</div>\n\n<blockquote>\n<p>A 1000x1000 randomly initialized grid running Game of life.</p>\n</blockquote>\n<hr>\n<p>This program was developed during the 2021/1 Parallel Computing (CCO0455) Computer Science graduate course at Universidade Federal de Goi√°s (UFG, Brazil).</p>\n","readingTime":"5 min read","title":"Cellular Automata Framework","slug":"2021-03-10-cellular-automata","date":"2021-03-10","urls":[{"cta":"Code","url":"https://github.com/bryanoliveira/cellular-automata"},{"cta":"Executable","url":"https://github.com/bryanoliveira/cellular-automata/releases"}],"type":"Project","tags":["project","parallel","cuda","opengl","game"],"image":"/img/cellular_automata.gif","description":"A <a href=\"https://en.wikipedia.org/wiki/Cellular_automaton\" target=\"_blank\">Cellular Automata</a> program built with C++, CUDA and OpenGL. The main objective of this project is to allow scaling up to a reasonably large number of cells while maintaining the code legibility and allowing for further customizations."},{"html":"<p>As my undergraduate thesis, I studied the impact of curiosity and intrinsic motivation as exploration strategy for deep reinforcement learning agents on sparse-reward robotic manipulator environments. We found that this approach encourages increasing exploratory behaviours even after the goal tasks were learned. Furthermore, we found that adding information about other objects&#39; states into the agent&#39;s observation is crucial for learning complex behaviours when no dense reward signal is provided. This study was inspired by the <a href=\"https://www.aicrowd.com/challenges/robot-open-ended-autonomous-learning-real\">Robot open-Ended Autonomous Learning</a> competition.</p>\n<p>To read the full report, <a href=\"https://github.com/bryanlincoln/undergraduate-thesis/blob/master/Text%20-%20Intrinsic%20motivation%20for%20robotic%20manipulation%20learning%20with%20sparse%20rewards.pdf\">click here</a> (Portuguese).</p>\n<div align=\"center\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/pick.gif\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/push.gif\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/reach.gif\">\n</div>\n\n<blockquote>\n<p>Learned policies for the tasks Pick And Place (left), Push (center) and Reach (right).</p>\n</blockquote>\n<h2 id=\"requirements\">Requirements</h2>\n<ul>\n<li>  <a href=\"https://docs.python.org/\">Python 3</a></li>\n<li>  <a href=\"http://pytorch.org/\">PyTorch</a></li>\n<li>  <a href=\"https://github.com/openai/gym\">OpenAI Gym</a></li>\n<li>  <a href=\"https://github.com/openai/baselines\">OpenAI baselines</a></li>\n<li>  <a href=\"https://github.com/jmichaux/gym-fetch\">Gym Fetch</a></li>\n</ul>\n<h2 id=\"usage\">Usage</h2>\n<p>To run the code, simply execute <code>python main.py</code> after installing all the requirements. There are many customizable hyperparemeters and configurations. You can see them with <code>python main.py --help</code>. The exact hyperparameters for this study&#39;s experiments can be found in the folder <code>experiments</code>.</p>\n<h2 id=\"credits\">Credits</h2>\n<p>This code was based on and adapted from</p>\n<ul>\n<li>  <a href=\"https://github.com/jmichaux/intrinsic-motivation\">Jon Michaux&#39;s implementation of intrinsic motivation</a> (which was used as starting point for running the experiments of this repo)</li>\n<li>  <a href=\"https://github.com/srama2512/curiosity-driven-exploration\">Santhosh Ramakrishnan&#39;s implementation of curiosity</a></li>\n<li>  <a href=\"https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail\">Ilya Kostrikov&#39; implementation of recent RL algorithms</a></li>\n<li>  <a href=\"https://github.com/openai/baselines\">OpenAI Baselines</a></li>\n<li>  <a href=\"https://github.com/cbschaff/pytorch-dl\">Chip Schaff&#39;s Deep Learning Library</a></li>\n</ul>\n<p>The inspiration and theoretic background was mainly based on</p>\n<ul>\n<li>  <a href=\"https://pathak22.github.io/noreward-rl/\">Curiosity-driven Exploration by Self-supervised Prediction</a></li>\n<li>  <a href=\"https://pathak22.github.io/large-scale-curiosity/\">Large-Scale Study of Curiosity-Driven Learning</a></li>\n</ul>\n<h2 id=\"results\">Results</h2>\n<h3 id=\"success-rate-charts\">Success Rate Charts</h3>\n<p>Pick And Place Task (left), Push Task (center) and Reach (right). Blue lines are results for vanilla PPO (baseline) and red lines for PPO + intrinsic motivation.</p>\n<div align=\"center\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/pick.png\"> \n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/push.png\"> \n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/reach.png\">\n</div>\n\n<h3 id=\"entropy-charts\"><a href=\"https://arxiv.org/abs/1811.11214\">Entropy</a> Charts</h3>\n<p>Pick And Place Task (left), Push Task (center) and Reach (right). Blue lines are results for vanilla PPO (baseline) and red lines for PPO + intrinsic motivation.</p>\n<div align=\"center\">\n<img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/pick_ent.png\"> \n<img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/push_ent.png\"> \n<img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/reach_ent.png\">\n</div>\n\n<h3 id=\"intrinsic-reward-charts\">Intrinsic Reward Charts</h3>\n<p>Pick And Place Task (left), Push Task (center) and Reach (right).</p>\n<div align=\"center\">\n<img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/pick_int.png\"> \n<img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/push_int.png\"> \n<img class=\"text-img mw-33\" src=\"https://github.com/bryanlincoln/undergraduate-thesis/raw/master/fig/preview/reach_int.png\">\n</div>\n\n<p>The interpretation of these curves can be found in my full report.</p>\n","readingTime":"2 min read","title":"Intrinsic motivation for robotic manipulation learning with sparse rewards","slug":"2019-12-10-intrinsic-motivation","date":"2019-12-10","urls":[{"cta":"Code","url":"https://github.com/bryanoliveira/intrinsic-motivation"},{"cta":"Paper","url":"https://github.com/bryanoliveira/undergraduate-thesis/blob/master/Text%20-%20Intrinsic%20motivation%20for%20robotic%20manipulation%20learning%20with%20sparse%20rewards.pdf"}],"type":"Undergraduate Thesis","tags":["research","publication"],"image":"/img/pick.gif","description":"Intrinsic motivation for robotic manipulation learning with sparse rewards - Study of the impact of curiosity and intrinsic motivation as an exploration strategy for deep reinforcement learning agents on sparse-reward robotic manipulator environments."},{"html":"<p>This is my code for the <a href=\"https://www.kaggle.com/c/bone-age-regression\">I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.</p>\n<p>This competition was inspired by <a href=\"https://www.kaggle.com/kmader/rsna-bone-age\">RSNA&#39;s Bone Age challenge</a>, in which given hand X-ray images, the model should predict the patient&#39;s bone age.</p>\n<div align=\"center\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanoliveira/bone-age-regression/raw/master/docs/ex1.png\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanoliveira/bone-age-regression/raw/master/docs/ex2.png\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanoliveira/bone-age-regression/raw/master/docs/ex3.png\">\n</div>\n\n<blockquote>\n<p>X-ray images provided in the competition&#39;s dataset.</p>\n</blockquote>\n<p>My final solution used a <a href=\"https://arxiv.org/abs/1512.03385\">ResNet50</a> architecture, a <a href=\"https://arxiv.org/abs/1908.03265\">Rectified Adam</a> optimizer and geometric data augmentations. This model achieved a Mean Average Error of 13.2 after 20 epochs of training, which I believe could be improved given more training time and a better preprocessing pipeline (e.g. using object detection to segment the hands and normalizing hand rotation). Unfortunately, I didn&#39;t save all the hyperparameters I experimented with (neither their results), but you&#39;ll find the ones I used for my last submission in the code.</p>\n<p>I used <a href=\"https://www.tensorflow.org/tensorboard\">tensorboard</a> to log the training curves and <a href=\"https://github.com/tqdm/tqdm\">tqdm</a> to track progress. I also used <a href=\"https://github.com/bryanlincoln/fcm-notifier\">FCMNotifier</a>, a tool I made to send logs as notifications to my phone.</p>\n<h2 id=\"requirements\">Requirements</h2>\n<p>See <a href=\"https://github.com/bryanlincoln/bone-age-regression/blob/master/requirements.txt\">requirements.txt</a>.</p>\n<h2 id=\"usage\">Usage</h2>\n<ul>\n<li>  Download the requirements with <code>pip install -r requirements.txt</code></li>\n<li>  Download the dataset and sample submission with <code>sh download_data.sh</code>. You may need to log in with your Kaggle account in order to do it.</li>\n<li>  Train the ResNet50 model with <code>python boneage.py</code></li>\n<li>  Try different models and hyperparameters by editing the training script or use the <code>boneage.ipynb</code> notebook to do it interactively.</li>\n</ul>\n<h2 id=\"credits\">Credits</h2>\n<p>I used the vision models already <a href=\"https://github.com/pytorch/vision/tree/master/torchvision/models\">implemented in torchvision</a> with slight changes. You can try other torchvision models by adding the <code>in_channels</code> parameter to generalize the number of input channels since torchvision models work with RGB images.</p>\n","readingTime":"2 min read","title":"Bone Age Regression","slug":"2019-11-10-bone-age-regression","date":"2019-11-10","urls":[{"cta":"Code","url":"https://github.com/bryanoliveira/bone-age-regression"}],"type":"Deep Learning","tags":["project","ai","deeplearning"],"image":"/img/bone.png","description":"This is my code for the <a href=\"https://www.kaggle.com/c/bone-age-regression\">I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice."},{"html":"<p>Quack is a Unity3D game made for the Global Game Jam 2019 themed &quot;What home means to you?&quot; (<a href=\"https://globalgamejam.org/2019/games/quack\">check out the game&#39;s entry here</a>).\nThe game consists of a happy chicken that wants to build a new home for its children. You have to collect sticks and group them on top of the main tree to make a lovely nest. This game was developed within 12 hours.</p>\n<div align=\"center\">\n \n<img class=\"text-img mw-50\" src=\"https://ggj.s3.amazonaws.com/styles/game_sidebar__wide/featured_image/2019/01/263393/menu.png?itok=veRqhjix&timestamp=1548611925\"/>\n<img class=\"text-img mw-50\" src=\"https://ggj.s3.amazonaws.com/styles/feature_image__wide/games/screenshots/ingame3_9.png?itok=Xuf3MZan&timestamp=1548611547\"/>\n\n</div>\n\n<h2 id=\"diversifiers\">Diversifiers</h2>\n<ul>\n<li>  Language-Independence - (Sponsored by Valve Software) - Create a game that can be understood regardless of which language the player speaks</li>\n<li>  Keep it simple - Make your game playable by people who can use no more than a D-pad plus 2 buttons, with hardware like an Xbox Adaptive Controller in mind.</li>\n<li>  Assetless - Create all visuals programmatically or in the scene editor, and avoid any importing of image files, sprite sheets, 3D models etc.</li>\n<li>  Super Secret Stash - Feature a hidden room within your game.</li>\n</ul>\n<h2 id=\"credits\">Credits</h2>\n<p>This game was made by a group of 3 computer science students located in Goi√¢nia, Brazil:</p>\n<ul>\n<li>  Bryan (me, <a href=\"mailto:&#x62;&#114;&#121;&#x61;&#x6e;&#x75;&#102;&#x67;&#x40;&#103;&#109;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#x6d;\">&#x62;&#114;&#121;&#x61;&#x6e;&#x75;&#102;&#x67;&#x40;&#103;&#109;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#x6d;</a>) programmed and modeled;</li>\n<li>  Luana (<a href=\"https://github.com/luanagbmartins\">@luanagbmartins</a> / <a href=\"mailto:&#108;&#x75;&#x61;&#x6e;&#97;&#103;&#98;&#x6d;&#97;&#114;&#x74;&#x69;&#x6e;&#x73;&#x40;&#103;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d;\">&#108;&#x75;&#x61;&#x6e;&#97;&#103;&#98;&#x6d;&#97;&#114;&#x74;&#x69;&#x6e;&#x73;&#x40;&#103;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d;</a>) programmed and designed the level;</li>\n<li>  Rennan (<a href=\"https://github.com/rennan11\">@rennan11</a> / <a href=\"mailto:&#114;&#101;&#x6e;&#x6e;&#x61;&#110;&#x65;&#x6c;&#105;&#x74;&#64;&#x67;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#111;&#109;\">&#114;&#101;&#x6e;&#x6e;&#x61;&#110;&#x65;&#x6c;&#105;&#x74;&#64;&#x67;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#111;&#109;</a>) designed the game and the sounds.</li>\n</ul>\n<p>In-game sound effects downloaded from Soundsnap.\nIn-game font &quot;Gloria Hallelujah&quot; by Kimberly Geswein, downloaded from Google Fonts.</p>\n","readingTime":"2 min read","title":"Quack","slug":"2019-01-10-quack","date":"2019-01-10","urls":[{"cta":"Code","url":"https://github.com/bryanoliveira/gjams-2019-quack"},{"cta":"Jam Entry","url":"https://globalgamejam.org/2019/games/quack"}],"type":"Game","tags":["project","game","jam","indie"],"image":"/img/quack.png","description":"Quack is a Unity3D game made for the Global Game Jam 2019 themed \"What home means to you?\". The game consists of a happy chicken that wants to build a new home for its children. You have to collect sticks and group them on top of the main tree to make a lovely nest. This game was developed within 12 hours."},{"html":"<p>3D Force simulator using only <a href=\"https://processing.org/\">Processing</a>&#39;s point() and line() functions. Uses Digital Differential Analyzer (DDA) to render lines between two points, Scan Line to render polygons, normal calculation to determine faces to render in 3D space and Newtonian physics. Written in Java.</p>\n<div align=\"center\">\n    <img class=\"text-img mw-100\" src=\"/img/rigidbody_physics.gif\"/>\n</div>\n\n<blockquote>\n<p>One of the project&#39;s scenes, where the cube is affected by gravity and the ground is not.</p>\n</blockquote>\n<p>The program interface allows for real-time selection, positioning, rotation, scaling and acceleration of objects. In a <a href=\"https://github.com/bryanoliveira/processing-3d-force-simulator/blob/fc899000baecf513cc3da4b38ab104cd4de260f7/Simulator/Projections.pde\">previous version</a> it also supported selecting between Cavalier, Cabinet, Isometric, Perspective-Z and Perspective-XZ projections.</p>\n<h2 id=\"usage\">Usage</h2>\n<ul>\n<li>  Clone this repository</li>\n<li>  Install <a href=\"https://processing.org/download/\">Processing</a></li>\n<li>  Open this project with Processing IDE or execute <code>processing-java --sketch=Simulator --force --run</code> in a CLI.</li>\n</ul>\n<hr>\n<p>This program was developed as the final project for the 2018/2 Computer Graphics (INF0037) class of Computer Science at Universidade Federal de Goi√°s (UFG, Brazil).</p>\n","readingTime":"1 min read","title":"3D Rendering & Force Simulator","slug":"2018-12-10-rigid-body-physics","date":"2018-12-10","urls":[{"cta":"Code","url":"https://github.com/bryanoliveira/processing-3d-force-simulator"}],"type":"Rendering","tags":["project","rendering","simulation"],"image":"/img/rigidbody_physics.gif","description":"3D Force simulator using only Processing's point() and line functions. Uses Digital Differential Analyzer (DDA) to render lines between two points, Scan Line to render polygons, normal calculation to determine faces to render in 3D space and Newtonian physics. Written in Java."},{"html":"<p>Hi! This is the development repo of <a href=\"https://www.facebook.com/NucleoPMec/\">Pequi Mec√¢nico</a> - INF&#39;s <strong>Very Small Size Soccer Team</strong>. Our team comprises several courses (Electrical Engineering, Computer Engineering, Software Engineering and Computer Science), all from Federal University of Goi√°s - <a href=\"https://www.ufg.br/\">UFG</a> - Goi√¢nia. Our repository is open because we understand that our greatest job is to add our research and knowledge to the academic and industrial world.</p>\n<p>You can find our Team Description Paper <a href=\"https://github.com/bryanoliveira/PY-VSSS-INF/blob/master/docs/TDP%20VSSS%20INF%202018.pdf\">here</a>. We are open to answer any questions and suggestions through our email <a href=\"mailto:&#112;&#101;&#113;&#117;&#x69;&#109;&#101;&#x63;&#97;&#x6e;&#105;&#99;&#x6f;&#x75;&#102;&#103;&#64;&#103;&#109;&#97;&#x69;&#108;&#x2e;&#99;&#111;&#x6d;\">&#112;&#101;&#113;&#117;&#x69;&#109;&#101;&#x63;&#97;&#x6e;&#105;&#99;&#x6f;&#x75;&#102;&#103;&#64;&#103;&#109;&#97;&#x69;&#108;&#x2e;&#99;&#111;&#x6d;</a>.</p>\n<h2 id=\"features\">Features</h2>\n<ul>\n<li>  Isolated modules for vision, strategy, control, communication, and interface</li>\n<li>  High-fidelity simulator made with MuJoCo</li>\n<li>  Qt interface</li>\n</ul>\n<div align=\"center\">\n    <a href=\"https://www.youtube.com/watch?v=JQVrX5h7u_8\">\n        <img class=\"text-img mw-100\" src=\"https://github.com/bryanoliveira/PY-VSSS-INF/raw/master/docs/images/Simulator.gif\"/>\n    </a>\n</div>\n\n<blockquote>\n<p>Our simulator running two instances of the same control system. Green arrows indicate the robot&#39;s movement direction (given by the vector field), and blue, yellow, and red arrows indicate goalie, defender and attacker&#39;s targets.</p>\n</blockquote>\n<h2 id=\"usage\">Usage</h2>\n<h3 id=\"dependencies\">Dependencies</h3>\n<p>Our code runs on all Python3-supported OS&#39;s (we recommend Python 3.4). To start using our software, you must install all requirements described on our requirements.txt file. You can easily do that by running:</p>\n<p><code>pip install -r requirements.txt</code></p>\n<p>We use MuJoCo as our simulation engine. Unfortunately, as MuJoCo is not free software, you must grab your license <a href=\"https://www.roboti.us/license.html\">here</a> to run our simulator.</p>\n<h3 id=\"executing\">Executing</h3>\n<p>To open the GUI we use on our competitions, run:</p>\n<p><code>python afrodite.py</code></p>\n<p>To open our simulator, run:</p>\n<p><code>python aether.py</code></p>\n<div align=\"center\">\n    <a href=\"https://www.youtube.com/watch?v=UBV4qlAJ-sc\">\n        <img class=\"text-img mw-100\" src=\"https://github.com/bryanoliveira/PY-VSSS-INF/raw/master/docs/images/Kick.gif\"/>\n    </a>\n</div>\n\n<h2 id=\"social-networks\">Social networks</h2>\n<p>Our activities and events always have updates. Follow us and get updated :D</p>\n<ul>\n<li>  <a href=\"https://www.instagram.com/pequimecanico/\">Instagram</a></li>\n<li>  <a href=\"https://www.facebook.com/NucleoPMec\">Facebook</a></li>\n</ul>\n","readingTime":"2 min read","title":"IEEE VSSS Team","slug":"2018-10-10-ieee-vsss-team","date":"2018-10-10","urls":[{"cta":"Code","url":"https://github.com/bryanoliveira/PY-VSSS-INF"},{"cta":"Simulator Demo","url":"https://www.youtube.com/watch?v=JQVrX5h7u_8"},{"cta":"Team Description Paper","url":"https://github.com/bryanoliveira/PY-VSSS-INF/blob/master/docs/TDP%20VSSS%20INF%202018.pdf"}],"type":"Robotics","tags":["project","robotics","leadership"],"image":"/img/vsss_cover.gif","description":"A stack consisting of image processing, computer vision, team coordination, navigation, control and communication software to compete in the 2018's Latin-American Robotics Competition for the Pequi Mec√¢nico UFG - INF's team."},{"html":"<p>In a world overrun by zombies, you must survive as long as possible and defeat different bosses while unlocking weapons, upgrades, equipment, characters, maps and much more. Reviving the classics of the &#39;80s and &#39;90s, Die Zombit is a retro wave top-down shooting game with an amazing soundtrack and addictive gameplay that guarantees many hours of fun. Check out its trailer <a href=\"https://www.youtube.com/watch?v=sO7FSZ3TJns\">here</a>:</p>\n<div align=\"center\">\n    <img src=\"img/zombit_walter.gif\" width=\"480\"/>\n</div>\n\n<p>I made this game during my first year in the Computer Science course. I&#39;ve learned a lot from this project, from software engineering to game design and a little bit of pixel art. I believe the project could be significantly improved using better design patterns, clearer abstractions and algorithmic complexity in mind. Yet, it is a fun game that you can <a href=\"https://play.google.com/store/apps/details?id=com.elitgames.zombit\">download</a> (an older version) in Play Store.</p>\n<div align=\"center\">\n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanoliveira/unity-zombit/raw/master/Images/3.png\"> \n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanoliveira/unity-zombit/raw/master/Images/2.png\"> \n    <img class=\"text-img mw-33\" src=\"https://github.com/bryanoliveira/unity-zombit/raw/master/Images/1.png\">\n</div>\n\n<h2 id=\"usage\">Usage</h2>\n<h3 id=\"running-a-pre-built-binary-android-and-windows-only\">Running a pre-built binary (Android and Windows only)</h3>\n<p>For the Android version, you may <a href=\"https://play.google.com/store/apps/details?id=com.elitgames.zombit\">head to the Play Store</a>.</p>\n<p>For the Windows version, do the following:</p>\n<ul>\n<li>Download Die.Zombit.[version].zip from the <a href=\"https://github.com/bryanoliveira/unity-zombit/releases\">latest release</a></li>\n<li>Extract the game folder</li>\n<li>Double click to run it.</li>\n</ul>\n<h3 id=\"buildingrunning-from-source\">Building/running from source</h3>\n<ul>\n<li>  Install Unity3D (tested for v2019.3)</li>\n<li>  Open the project folder</li>\n<li>  Hit Play and have fun!</li>\n</ul>\n<h2 id=\"next-steps\">Next steps</h2>\n<p>This version is an unfinished project that rethinks the UI, weapon management and overall objectives. It was made as an indie game event demo and some things are broken. The fixes and new features I plan to add include:</p>\n<ul>\n<li>  Fix joystick and touchscreen support</li>\n<li>  Fix pause menu UI</li>\n<li>  Fix end game UI</li>\n<li>  Add multiplayer support</li>\n</ul>\n<h2 id=\"more-gifs\">More GIFs</h2>\n<div align=\"center\">\n    <img src=\"img/zombit_monster.gif\" width=\"480\"/><br/>\n    <img src=\"img/zombit_round_up.gif\" width=\"480\"/>\n</div>\n\n<h2 id=\"credits\">Credits</h2>\n<ul>\n<li>Soundtracks by<ul>\n<li>  <a href=\"https://soundcloud.com/bossfightswe\">Bossfight</a></li>\n<li>  <a href=\"https://soundcloud.com/ultrasyd\">Ultrasyd</a></li>\n<li>  <a href=\"https://soundcloud.com/dunderpatrullen\">Dunderpatrullen</a></li>\n<li>  <a href=\"https://soundcloud.com/detiouss\">Detious</a> &amp; <a href=\"https://soundcloud.com/lockyn\">Lockyn</a></li>\n</ul>\n</li>\n</ul>\n","readingTime":"2 min read","title":"Die Zombit","slug":"2015-06-10-die-zombit","date":"2015-06-10","urls":[{"cta":"Code","url":"https://github.com/bryanoliveira/unity-zombit"},{"cta":"Store","url":"https://play.google.com/store/apps/details?id=com.elitgames.zombit"},{"cta":"Trailer","url":"https://www.youtube.com/watch?v=sO7FSZ3TJns"}],"type":"Game","tags":["project","game","indie"],"image":"/img/zombit_cover.gif","description":"Reviving the classics of the 80's and 90's, Die Zombit is a retrowave top-down shooting game that has a striking soundtrack and an addictive gameplay which guarantee many hours of fun."}]