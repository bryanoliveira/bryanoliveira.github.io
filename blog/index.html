<!DOCTYPE html> <html lang=en> <head> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169339523-1"></script> <script> window.dataLayer = window.dataLayer || []
            function gtag() {
                dataLayer.push(arguments)
            }
            gtag('js', new Date())

            gtag('config', 'UA-169339523-1') </script> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1,shrink-to-fit=no" name=viewport> <meta content="Bryan Oliveira" name=author> <meta content=#FFFFFF name=theme-color> <title>Bryan Oliveira</title> <base href=/ > <link href=/manifest.json rel=manifest crossorigin=use-credentials> <link href=/img/icon.png rel=icon type=image/png> <link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400&display=swap" rel=stylesheet> <link href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-dark-reasonable.min.css rel=stylesheet> <link href=/css/fonts.css rel=stylesheet> <link href=/css/bootstrap.css rel=stylesheet> <link href=/css/global.css rel=stylesheet> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,(function(a,b,c,d,e,f){return {posts:[{html:"\u003Cp\u003EA \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCellular_automaton\"\u003ECellular Automata\u003C\u002Fa\u003E program built with C++, CUDA and OpenGL. It&#39;s built to run on a GPU but it also supports CPU-only execution (mainly for relative speedup comparisons). On the right there&#39;s an example execution of \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FConway%27s_Game_of_Life\"\u003EConway&#39;s Game of Life\u003C\u002Fa\u003E on a 100x100 randomly initialized grid.\u003C\u002Fp\u003E\n\u003Cp\u003EThe main objective of this project is to allow scaling up to a reasonably large number of cells while maintaining the code legibility and allowing for further customizations. It supports command line arguments to set up quick configs (run \u003Ccode\u003E.\u002Fautomata -h\u003C\u002Fcode\u003E for details) like headless mode (which is significantly faster) and initial patterns (which can be loaded from the \u003Ccode\u003Epatterns\u003C\u002Fcode\u003E folder). It doesn&#39;t yet support the definition of evolution rules at runtime or lattice size inference, but I&#39;m working on that.\u003C\u002Fp\u003E\n\u003Cp\u003EThis program can currently evolve a dense &amp; high entropy 182.25 million cell Game of Life grid (13500x13500) with rendering enabled with up to 320 generations per second on a Ryzen 7 3700X \u002F RTX 3080 using up to 200MB RAM and 8.5GB VRAM (which is the actual scaling limiter).\u003C\u002Fp\u003E\n\u003Cp\u003EThe ability to evolve and render such large grids allows the program to run some really interesting patterns, like evolving the Game of Life \u003Cem\u003Ewithin\u003C\u002Fem\u003E the Game of Life:\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fcellular-automata\u002Fraw\u002Fmaster\u002Fdocs\u002Fzoom.gif\"\u003E\n\u003C\u002Fdiv\u003E\n\u003Cbr\u002F\u003E\n\n\u003Cp\u003EIn the GIF above we&#39;re running a 12300x12300 grid using Game of Life rules to evolve a pattern known as \u003Ca href=\"http:\u002F\u002Fb3s23life.blogspot.com\u002F2006_09_01_archive.html\"\u003EMeta-Toad\u003C\u002Fa\u003E. It uses a grid of \u003Ca href=\"https:\u002F\u002Fwww.conwaylife.com\u002Fwiki\u002FOTCA_metapixel\"\u003EOTCA Metapixels\u003C\u002Fa\u003E and requires about 35 thousand generations of the underlying automaton to represent a single generation of the meta-grid. The pattern being evolved by the meta-grid is known as \u003Ca href=\"https:\u002F\u002Fwww.conwaylife.com\u002Fwiki\u002FToad\"\u003EToad\u003C\u002Fa\u003E:\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fcellular-automata\u002Fraw\u002Fmaster\u002Fdocs\u002Ftoad.gif\" align=\"center\" width=\"100\"\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Cbr \u002F\u003E\n\n\u003Ch2 id=\"requirements\"\u003ERequirements\u003C\u002Fh2\u003E\n\u003Cp\u003ETo run the program you&#39;ll need:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Debian-like linux distro (I only tested this on Ubuntu 20)\u003C\u002Fli\u003E\n\u003Cli\u003EOpenGL (GLEW and GLUT)\u003Cul\u003E\n\u003Cli\u003E  e.g. \u003Ccode\u003Esudo apt-get install libglew2.1 freeglut3-dev\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fdeveloper.nvidia.com\u002Fcuda-downloads\"\u003ECUDA\u003C\u002Fa\u003E (nvcc) and CUDA runtime libraries\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003ETo build it from source you&#39;ll also need:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003Eg++ (C++ 17) and \u003Cem\u003Emake\u003C\u002Fem\u003E\u003Cul\u003E\n\u003Cli\u003E  e.g. \u003Ccode\u003Esudo apt install build-essential\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E  Boost C++ Library (program_options module)\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EIt is possible to run this program in a CPU-only mode, so if you don&#39;t have a CUDA-capable video card you may skip the last step. For that to work you will need to run the program with \u003Ccode\u003E.\u002Fautomata --cpu\u003C\u002Fcode\u003E and disable \u003Ccode\u003E*.cu\u003C\u002Fcode\u003E file compilation in the \u003Ccode\u003EMakefile\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\n\u003Ch2 id=\"usage\"\u003EUsage\u003C\u002Fh2\u003E\n\u003Ch3 id=\"executing-a-pre-built-binary-linux-x64--cuda-only\"\u003EExecuting a pre-built binary (Linux x64 + CUDA only)\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Download \u003Ccode\u003Ecellular-automata-linux64.zip\u003C\u002Fcode\u003E from the \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fcellular-automata\u002Freleases\"\u003Elatest release\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  Extract the executable (\u003Ccode\u003Eautomata\u003C\u002Fcode\u003E) and the \u003Ccode\u003Epatterns\u003C\u002Fcode\u003E folder\u003C\u002Fli\u003E\n\u003Cli\u003E  Install OpenGL and CUDA from the requirements above\u003C\u002Fli\u003E\n\u003Cli\u003E  Run \u003Ccode\u003E.\u002Fautomata -h\u003C\u002Fcode\u003E to see all the available options\u003C\u002Fli\u003E\n\u003Cli\u003E  Run the program with \u003Ccode\u003E.\u002Fautomata --render\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EIf your GPU has enough VRAM (&gt;= 8 GB), you may be able to reproduce the Meta-Toad simulation above. Run \u003Ccode\u003E.\u002Fautomata -r -x 12300 -y 12300 -p 0 -f patterns\u002Fmeta-toad.rle\u003C\u002Fcode\u003E to try it out!\u003C\u002Fp\u003E\n\u003Ch3 id=\"building-from-source\"\u003EBuilding From Source\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Install the requirements\u003C\u002Fli\u003E\n\u003Cli\u003E  Clone this repository\u003C\u002Fli\u003E\n\u003Cli\u003EBuilding and executing:\u003Cul\u003E\n\u003Cli\u003E  Run \u003Ccode\u003Emake\u003C\u002Fcode\u003E to build and run\u003C\u002Fli\u003E\n\u003Cli\u003E  Run \u003Ccode\u003Emake build\u003C\u002Fcode\u003E to build\u003C\u002Fli\u003E\n\u003Cli\u003E  Run \u003Ccode\u003Emake run\u003C\u002Fcode\u003E to run with default parameters\u003C\u002Fli\u003E\n\u003Cli\u003E  Run \u003Ccode\u003Emake clean\u003C\u002Fcode\u003E to remove generated files\u003C\u002Fli\u003E\n\u003Cli\u003E  Run \u003Ccode\u003Emake profile\u003C\u002Fcode\u003E to run \u003Ca href=\"https:\u002F\u002Fdeveloper.nvidia.com\u002Fnsight-systems\"\u003ENVIDIA&#39;s nsys\u003C\u002Fa\u003E profiling.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3 id=\"runtime-controls\"\u003ERuntime Controls\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli\u003EBasic controls:\u003Cul\u003E\n\u003Cli\u003E  \u003Cstrong\u003Espace\u003C\u002Fstrong\u003E pauses\u002Fresumes the simulation;\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Cstrong\u003Eenter\u002Freturn\u003C\u002Fstrong\u003E runs a single generation;\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Cstrong\u003Eleft mouse click\u003C\u002Fstrong\u003E translates the grid relative to the max resolution\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Cstrong\u003Ectrl + left mouse click\u003C\u002Fstrong\u003E translates the camera relative to the world\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Cstrong\u003Emouse scroll\u003C\u002Fstrong\u003E zooms the grid in and out, relative to the max resolution\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Cstrong\u003Ectrl + mouse scroll\u003C\u002Fstrong\u003E zooms the camera, relative to the world\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Cstrong\u003Emiddle mouse click\u003C\u002Fstrong\u003E resets scale and translation\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"references\"\u003EReferences\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  What are \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCellular_automaton\"\u003ECellular Automata\u003C\u002Fa\u003E?\u003C\u002Fli\u003E\n\u003Cli\u003E  What is \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FConway%27s_Game_of_Life\"\u003EConway&#39;s Game of Life\u003C\u002Fa\u003E?\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"http:\u002F\u002Fgolly.sourceforge.net\u002F\"\u003EGolly\u003C\u002Fa\u003E: an open source cellular automata simulator that supports several Game of Life and other automata algorithms;\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fcopy.sh\u002Flife\u002F\"\u003ELife\u003C\u002Fa\u003E: an open source JavaScript implementation of Game of Life that runs in the browser;\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"http:\u002F\u002Fb3s23life.blogspot.com\u002F2006_09_01_archive.html\"\u003EConway&#39;s Life: Work in Progress\u003C\u002Fa\u003E: where I got the initial pattern for the Meta-Toad;\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fblog.amandaghassaei.com\u002F2020\u002F05\u002F01\u002Fthe-recursive-universe\u002F\"\u003EThe Recursive Universe\u003C\u002Fa\u003E: explores and explains how some of the meta-patterns work;\u003C\u002Fli\u003E\n\u003Cli\u003E  What are \u003Ca href=\"https:\u002F\u002Fwww.conwaylife.com\u002Fwiki\u002FOTCA_metapixel\"\u003EOTCA Metapixels\u003C\u002Fa\u003E?\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"bonus\"\u003EBonus\u003C\u002Fh2\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fcellular-automata\u002Fraw\u002Fmaster\u002Fdocs\u002F1000x1000.gif\" alt=\"1000x1000 grid (click to open)\"\u003E\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cp\u003EA 1000x1000 randomly initialized grid running Game of life.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Chr\u003E\n\u003Cp\u003EThis program was developed during the 2021\u002F1 Parallel Computing (CCO0455) Computer Science graduate course at Universidade Federal de Goiás (UFG, Brazil).\u003C\u002Fp\u003E\n",readingTime:"4 min read",title:"Cellular Automata Framework",slug:"2021-03-10-cellular-automata",date:"2021-03-10",urls:[{cta:a,url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fcellular-automata"}],type:"Project",tags:[b,"parallel","cuda","opengl",d],image:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fcellular-automata\u002Fraw\u002Fmaster\u002Fdocs\u002F100x100.gif",description:"A \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCellular_automaton\" target=\"_blank\"\u003ECellular Automata\u003C\u002Fa\u003E program built with C++, CUDA and OpenGL. The main objective of this project is to allow scaling up to a reasonably large number of cells while maintaining the code legibility and allowing for further customizations."},{html:"\u003Cp\u003EAs my undergraduate thesis, I studied the impact of curiosity and intrinsic motivation as exploration strategy for deep reinforcement learning agents on sparse-reward robotic manipulator environments. We found that this approach encourages increasing exploratory behaviours even after the goal tasks were learned. Furthermore, we found that adding information about other objects&#39; states into the agent&#39;s observation is crucial for learning complex behaviours when no dense reward signal is provided. This study was inspired by the \u003Ca href=\"https:\u002F\u002Fwww.aicrowd.com\u002Fchallenges\u002Frobot-open-ended-autonomous-learning-real\"\u003ERobot open-Ended Autonomous Learning\u003C\u002Fa\u003E competition.\u003C\u002Fp\u003E\n\u003Cp\u003ETo read the full report, \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fblob\u002Fmaster\u002FText%20-%20Intrinsic%20motivation%20for%20robotic%20manipulation%20learning%20with%20sparse%20rewards.pdf\"\u003Eclick here\u003C\u002Fa\u003E (Portuguese).\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpick.gif\" width=\"230\" height=\"150\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpush.gif\" width=\"230\" height=\"150\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Freach.gif\" width=\"230\" height=\"150\"\u003E\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cp\u003ELearned policies for the tasks Pick And Place (left), Push (center) and Reach (right).\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Ch2 id=\"requirements\"\u003ERequirements\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fdocs.python.org\u002F\"\u003EPython 3\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"http:\u002F\u002Fpytorch.org\u002F\"\u003EPyTorch\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fopenai\u002Fgym\"\u003EOpenAI Gym\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fopenai\u002Fbaselines\"\u003EOpenAI baselines\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fjmichaux\u002Fgym-fetch\"\u003EGym Fetch\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"usage\"\u003EUsage\u003C\u002Fh2\u003E\n\u003Cp\u003ETo run the code, simply execute \u003Ccode\u003Epython main.py\u003C\u002Fcode\u003E after installing all the requirements. There are many customizable hyperparemeters and configurations. You can see them with \u003Ccode\u003Epython main.py --help\u003C\u002Fcode\u003E. The exact hyperparameters for this study&#39;s experiments can be found in the folder \u003Ccode\u003Eexperiments\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\n\u003Ch2 id=\"credits\"\u003ECredits\u003C\u002Fh2\u003E\n\u003Cp\u003EThis code was based on and adapted from\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fjmichaux\u002Fintrinsic-motivation\"\u003EJon Michaux&#39;s implementation of intrinsic motivation\u003C\u002Fa\u003E (which was used as starting point for running the experiments of this repo)\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsrama2512\u002Fcuriosity-driven-exploration\"\u003ESanthosh Ramakrishnan&#39;s implementation of curiosity\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fikostrikov\u002Fpytorch-a2c-ppo-acktr-gail\"\u003EIlya Kostrikov&#39; implementation of recent RL algorithms\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fopenai\u002Fbaselines\"\u003EOpenAI Baselines\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fcbschaff\u002Fpytorch-dl\"\u003EChip Schaff&#39;s Deep Learning Library\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EThe inspiration and theoretic background was mainly based on\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fpathak22.github.io\u002Fnoreward-rl\u002F\"\u003ECuriosity-driven Exploration by Self-supervised Prediction\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fpathak22.github.io\u002Flarge-scale-curiosity\u002F\"\u003ELarge-Scale Study of Curiosity-Driven Learning\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"results\"\u003EResults\u003C\u002Fh2\u003E\n\u003Ch3 id=\"success-rate-charts\"\u003ESuccess Rate Charts\u003C\u002Fh3\u003E\n\u003Cp\u003EPick And Place Task (left), Push Task (center) and Reach (right). Blue lines are results for vanilla PPO (baseline) and red lines for PPO + intrinsic motivation.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpick.png\" width=\"230\" height=\"170\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpush.png\" width=\"230\" height=\"170\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Freach.png\" width=\"230\" height=\"170\"\u003E\u003C\u002Fp\u003E\n\u003Ch3 id=\"entropy-charts\"\u003E\u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1811.11214\"\u003EEntropy\u003C\u002Fa\u003E Charts\u003C\u002Fh3\u003E\n\u003Cp\u003EPick And Place Task (left), Push Task (center) and Reach (right). Blue lines are results for vanilla PPO (baseline) and red lines for PPO + intrinsic motivation.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpick_ent.png\" width=\"230\" height=\"170\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpush_ent.png\" width=\"230\" height=\"170\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Freach_ent.png\" width=\"230\" height=\"170\"\u003E\u003C\u002Fp\u003E\n\u003Ch3 id=\"intrinsic-reward-charts\"\u003EIntrinsic Reward Charts\u003C\u002Fh3\u003E\n\u003Cp\u003EPick And Place Task (left), Push Task (center) and Reach (right).\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpick_int.png\" width=\"230\" height=\"170\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Fpush_int.png\" width=\"230\" height=\"170\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fundergraduate-thesis\u002Fraw\u002Fmaster\u002Ffig\u002Fpreview\u002Freach_int.png\" width=\"230\" height=\"170\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EThe interpretation of these curves can be found in my full report.\u003C\u002Fp\u003E\n",readingTime:c,title:"Intrinsic motivation for robotic manipulation learning with sparse rewards",slug:"2019-12-10-intrinsic-motivation",date:"2019-12-10",urls:[{cta:a,url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fintrinsic-motivation"},{cta:"Paper",url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fundergraduate-thesis\u002Fblob\u002Fmaster\u002FText%20-%20Intrinsic%20motivation%20for%20robotic%20manipulation%20learning%20with%20sparse%20rewards.pdf"}],type:"Undergraduate Thesis",tags:["research","publication"],image:"\u002Fimg\u002Fpick.gif",description:"Intrinsic motivation for robotic manipulation learning with sparse rewards - Study of the impact of curiosity and intrinsic motivation as an exploration strategy for deep reinforcement learning agents on sparse-reward robotic manipulator environments."},{html:"\u003Cp\u003EThis is my code for the \u003Ca href=\"https:\u002F\u002Fwww.kaggle.com\u002Fc\u002Fbone-age-regression\"\u003EI2A2 Bone Age Regression competition\u003C\u002Fa\u003E. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.\u003C\u002Fp\u003E\n\u003Cp\u003EThis competition was inspired by \u003Ca href=\"https:\u002F\u002Fwww.kaggle.com\u002Fkmader\u002Frsna-bone-age\"\u003ERSNA&#39;s Bone Age challenge\u003C\u002Fa\u003E, in which given hand X-ray images, the model should predict the patient&#39;s bone age.\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression\u002Fraw\u002Fmaster\u002Fdocs\u002Fex1.png\" width=\"230\" height=\"320\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression\u002Fraw\u002Fmaster\u002Fdocs\u002Fex2.png\" width=\"230\" height=\"320\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression\u002Fraw\u002Fmaster\u002Fdocs\u002Fex3.png\" width=\"230\" height=\"320\"\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003EX-ray images provided in the competition&#39;s dataset.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Cp\u003EMy final solution used a \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1512.03385\"\u003EResNet50\u003C\u002Fa\u003E architecture, a \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1908.03265\"\u003ERectified Adam\u003C\u002Fa\u003E optimizer and geometric data augmentations. This model achieved a Mean Average Error of 13.2 after 20 epochs of training, which I believe could be improved given more training time and a better preprocessing pipeline (e.g. using object detection to segment the hands and normalizing hand rotation). Unfortunately, I didn&#39;t save all the hyperparameters I experimented with (neither their results), but you&#39;ll find the ones I used for my last submission in the code.\u003C\u002Fp\u003E\n\u003Cp\u003EI used \u003Ca href=\"https:\u002F\u002Fwww.tensorflow.org\u002Ftensorboard\"\u003Etensorboard\u003C\u002Fa\u003E to log the training curves and \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ftqdm\u002Ftqdm\"\u003Etqdm\u003C\u002Fa\u003E to track progress. I also used \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Ffcm-notifier\"\u003EFCMNotifier\u003C\u002Fa\u003E, a tool I made to send logs as notifications to my phone.\u003C\u002Fp\u003E\n\u003Ch2 id=\"requirements\"\u003ERequirements\u003C\u002Fh2\u003E\n\u003Cp\u003ESee \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fbone-age-regression\u002Fblob\u002Fmaster\u002Frequirements.txt\"\u003Erequirements.txt\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Ch2 id=\"usage\"\u003EUsage\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Download the requirements with \u003Ccode\u003Epip install -r requirements.txt\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  Download the dataset and sample submission with \u003Ccode\u003Esh download_data.sh\u003C\u002Fcode\u003E. You may need to log in with your Kaggle account in order to do it.\u003C\u002Fli\u003E\n\u003Cli\u003E  Train the ResNet50 model with \u003Ccode\u003Epython boneage.py\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  Try different models and hyperparameters by editing the training script or use the \u003Ccode\u003Eboneage.ipynb\u003C\u002Fcode\u003E notebook to do it interactively.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"credits\"\u003ECredits\u003C\u002Fh2\u003E\n\u003Cp\u003EI used the vision models already \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fpytorch\u002Fvision\u002Ftree\u002Fmaster\u002Ftorchvision\u002Fmodels\"\u003Eimplemented in torchvision\u003C\u002Fa\u003E with slight changes. You can try other torchvision models by adding the \u003Ccode\u003Ein_channels\u003C\u002Fcode\u003E parameter to generalize the number of input channels since torchvision models work with RGB images.\u003C\u002Fp\u003E\n",readingTime:c,title:"Bone Age Regression",slug:"2019-11-10-bone-age-regression",date:"2019-11-10",urls:[{cta:a,url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression"}],type:"Deep Learning",tags:[b,"ai","deeplearning"],image:"\u002Fimg\u002Fbone.png",description:"This is my code for the \u003Ca href=\"https:\u002F\u002Fwww.kaggle.com\u002Fc\u002Fbone-age-regression\"\u003EI2A2 Bone Age Regression competition\u003C\u002Fa\u003E. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice."},{html:"\u003Cp\u003EQuack is a Unity3D game made for the Global Game Jam 2019 themed &quot;What home means to you?&quot; (\u003Ca href=\"https:\u002F\u002Fglobalgamejam.org\u002F2019\u002Fgames\u002Fquack\"\u003Echeck out the game&#39;s entry here\u003C\u002Fa\u003E).\nThe game consists of a happy chicken that wants to build a new home for its children. You have to collect sticks and group them on top of the main tree to make a lovely nest. This game was developed within 12 hours.\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n \n\u003Cimg src=\"https:\u002F\u002Fggj.s3.amazonaws.com\u002Fstyles\u002Fgame_sidebar__wide\u002Ffeatured_image\u002F2019\u002F01\u002F263393\u002Fmenu.png?itok=veRqhjix&timestamp=1548611925\" width=\"300\"\u002F\u003E\n\u003Cimg src=\"https:\u002F\u002Fggj.s3.amazonaws.com\u002Fstyles\u002Ffeature_image__wide\u002Fgames\u002Fscreenshots\u002Fingame3_9.png?itok=Xuf3MZan&timestamp=1548611547\" width=\"300\"\u002F\u003E\n\n\u003C\u002Fdiv\u003E\n\u003Cbr\u002F\u003E\n\n\u003Ch2 id=\"diversifiers\"\u003EDiversifiers\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Language-Independence - (Sponsored by Valve Software) - Create a game that can be understood regardless of which language the player speaks\u003C\u002Fli\u003E\n\u003Cli\u003E  Keep it simple - Make your game playable by people who can use no more than a D-pad plus 2 buttons, with hardware like an Xbox Adaptive Controller in mind.\u003C\u002Fli\u003E\n\u003Cli\u003E  Assetless - Create all visuals programmatically or in the scene editor, and avoid any importing of image files, sprite sheets, 3D models etc.\u003C\u002Fli\u003E\n\u003Cli\u003E  Super Secret Stash - Feature a hidden room within your game.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"credits\"\u003ECredits\u003C\u002Fh2\u003E\n\u003Cp\u003EThis game was made by a group of 3 computer science students located in Goiânia, Brazil:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Bryan (me, \u003Ca href=\"mailto:&#x62;&#x72;&#x79;&#x61;&#x6e;&#x75;&#x66;&#103;&#64;&#x67;&#x6d;&#x61;&#x69;&#108;&#x2e;&#x63;&#x6f;&#109;\"\u003E&#x62;&#x72;&#x79;&#x61;&#x6e;&#x75;&#x66;&#103;&#64;&#x67;&#x6d;&#x61;&#x69;&#108;&#x2e;&#x63;&#x6f;&#109;\u003C\u002Fa\u003E) programmed and modeled;\u003C\u002Fli\u003E\n\u003Cli\u003E  Luana (\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fluanagbmartins\"\u003E@luanagbmartins\u003C\u002Fa\u003E \u002F \u003Ca href=\"mailto:&#x6c;&#117;&#97;&#110;&#x61;&#103;&#98;&#109;&#x61;&#114;&#116;&#x69;&#x6e;&#x73;&#x40;&#x67;&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;&#111;&#x6d;\"\u003E&#x6c;&#117;&#97;&#110;&#x61;&#103;&#98;&#109;&#x61;&#114;&#116;&#x69;&#x6e;&#x73;&#x40;&#x67;&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;&#111;&#x6d;\u003C\u002Fa\u003E) programmed and designed the level;\u003C\u002Fli\u003E\n\u003Cli\u003E  Rennan (\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Frennan11\"\u003E@rennan11\u003C\u002Fa\u003E \u002F \u003Ca href=\"mailto:&#x72;&#x65;&#110;&#110;&#x61;&#x6e;&#x65;&#x6c;&#x69;&#x74;&#x40;&#x67;&#x6d;&#x61;&#x69;&#108;&#46;&#x63;&#111;&#109;\"\u003E&#x72;&#x65;&#110;&#110;&#x61;&#x6e;&#x65;&#x6c;&#x69;&#x74;&#x40;&#x67;&#x6d;&#x61;&#x69;&#108;&#46;&#x63;&#111;&#109;\u003C\u002Fa\u003E) designed the game and the sounds.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EIn-game sound effects downloaded from Soundsnap.\nIn-game font &quot;Gloria Hallelujah&quot; by Kimberly Geswein, downloaded from Google Fonts.\u003C\u002Fp\u003E\n",readingTime:c,title:"Quack",slug:"2019-01-10-quack",date:"2019-01-10",urls:[{cta:a,url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fgjams-2019-quack"}],type:e,tags:[b,d,"jam",f],image:"\u002Fimg\u002Fquack.png",description:"Quack is a Unity3D game made for the Global Game Jam 2019 themed \"What home means to you?\". The game consists of a happy chicken that wants to build a new home for its children. You have to collect sticks and group them on top of the main tree to make a lovely nest. This game was developed within 12 hours."},{html:"\u003Cp\u003E3D Rigid Body Physics simulator using only \u003Ca href=\"https:\u002F\u002Fprocessing.org\u002F\"\u003EProcessing\u003C\u002Fa\u003E&#39;s point() and line() functions. Uses Digital Differential Analyzer (DDA) to render lines between two points, Scan Line to render polygons, normal calculation to determine faces to render in 3D space and Newtonian physics. Written in Java.\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fraw.githubusercontent.com\u002Fbryanlincoln\u002Fcg-processing-simulator\u002Fmaster\u002FDemo.gif\" width=\"600\"\u002F\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003EOne of the project&#39;s scenes, where one cube is affected by gravity (red) and the other is not (blue).\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Cp\u003EThe program interface allows for real-time selection, positioning, rotation, scaling and acceleration of objects. In a \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fprocessing-physics-simulator\u002Fblob\u002Ffc899000baecf513cc3da4b38ab104cd4de260f7\u002FSimulator\u002FProjections.pde\"\u003Eprevious version\u003C\u002Fa\u003E it also supported selecting between Cavalier, Cabinet, Isometric, Perspective-Z and Perspective-XZ projections.\u003C\u002Fp\u003E\n\u003Ch2 id=\"usage\"\u003EUsage\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Clone this repository\u003C\u002Fli\u003E\n\u003Cli\u003E  Install \u003Ca href=\"https:\u002F\u002Fprocessing.org\u002Fdownload\u002F\"\u003EProcessing\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  Open this project with Processing IDE or execute \u003Ccode\u003Eprocessing-java --sketch=Simulator --force --run\u003C\u002Fcode\u003E in a CLI.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Chr\u003E\n\u003Cp\u003EThis program was developed as the final project for the 2018\u002F2 Computer Graphics (INF0037) class of Computer Science at Universidade Federal de Goiás (UFG, Brazil).\u003C\u002Fp\u003E\n",readingTime:"1 min read",title:"Rigid Body Physics Simulator",slug:"2018-12-10-rigid-body-physics",date:"2018-12-10",urls:[{cta:a,url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fprocessing-physics-simulator"}],type:"Rendering",tags:[b,"rendering","simulation"],image:"\u002Fimg\u002Frigidbody_physics.gif",description:"3D Rigid Body Physics simulator using only Processing's point() and line functions. Uses Digital Differential Analyzer (DDA) to render lines between two points, Scan Line to render polygons, normal calculation to determine faces to render in 3D space and Newtonian physics. Written in Java."},{html:"\u003Cp\u003EHi! This is the development repo of \u003Ca href=\"https:\u002F\u002Fwww.facebook.com\u002FNucleoPMec\u002F\"\u003EPequi Mecânico\u003C\u002Fa\u003E - INF&#39;s \u003Cstrong\u003EVery Small Size Soccer Team\u003C\u002Fstrong\u003E. Our team comprises several courses (Electrical Engineering, Computer Engineering, Software Engineering and Computer Science), all from Federal University of Goiás - \u003Ca href=\"https:\u002F\u002Fwww.ufg.br\u002F\"\u003EUFG\u003C\u002Fa\u003E - Goiânia. Our repository is open because we understand that our greatest job is to add our research and knowledge to the academic and industrial world.\u003C\u002Fp\u003E\n\u003Cp\u003EYou can find our Team Description Paper \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002FPY-VSSS-INF\u002Fblob\u002Fmaster\u002Fdocs\u002FTDP%20VSSS%20INF%202018.pdf\"\u003Ehere\u003C\u002Fa\u003E. We are open to answer any questions and suggestions through our email \u003Ca href=\"mailto:&#112;&#101;&#113;&#x75;&#105;&#x6d;&#x65;&#99;&#97;&#x6e;&#105;&#x63;&#x6f;&#117;&#x66;&#x67;&#x40;&#103;&#x6d;&#x61;&#105;&#x6c;&#46;&#99;&#111;&#109;\"\u003E&#112;&#101;&#113;&#x75;&#105;&#x6d;&#x65;&#99;&#97;&#x6e;&#105;&#x63;&#x6f;&#117;&#x66;&#x67;&#x40;&#103;&#x6d;&#x61;&#105;&#x6c;&#46;&#99;&#111;&#109;\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Ch2 id=\"features\"\u003EFeatures\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Isolated modules for vision, strategy, control, communication, and interface\u003C\u002Fli\u003E\n\u003Cli\u003E  High-fidelity simulator made with MuJoCo\u003C\u002Fli\u003E\n\u003Cli\u003E  Qt interface\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=JQVrX5h7u_8\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002FPY-VSSS-INF\u002Fraw\u002Fmaster\u002Fdocs\u002Fimages\u002FSimulator.gif\" width=\"550\"\u002F\u003E\n\u003C\u002Fa\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003EOur simulator running two instances of the same control system. Green arrows indicate the robot&#39;s movement direction (given by the vector field), and blue, yellow, and red arrows indicate goalie, defender and attacker&#39;s targets.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Ch2 id=\"usage\"\u003EUsage\u003C\u002Fh2\u003E\n\u003Ch3 id=\"dependencies\"\u003EDependencies\u003C\u002Fh3\u003E\n\u003Cp\u003EOur code runs on all Python3-supported OS&#39;s (we recommend Python 3.4). To start using our software, you must install all requirements described on our requirements.txt file. You can easily do that by running:\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ccode\u003Epip install -r requirements.txt\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EWe use MuJoCo as our simulation engine. Unfortunately, as MuJoCo is not free software, you must grab your license \u003Ca href=\"https:\u002F\u002Fwww.roboti.us\u002Flicense.html\"\u003Ehere\u003C\u002Fa\u003E to run our simulator.\u003C\u002Fp\u003E\n\u003Ch3 id=\"executing\"\u003EExecuting\u003C\u002Fh3\u003E\n\u003Cp\u003ETo open the GUI we use on our competitions, run:\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ccode\u003Epython afrodite.py\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\n\u003Cp\u003ETo open our simulator, run:\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ccode\u003Epython aether.py\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=UBV4qlAJ-sc\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002FPY-VSSS-INF\u002Fraw\u002Fmaster\u002Fdocs\u002Fimages\u002FKick.gif\" width=\"600\"\u002F\u003E\n\u003C\u002Fa\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Ch2 id=\"social-networks\"\u003ESocial networks\u003C\u002Fh2\u003E\n\u003Cp\u003EOur activities and events always have updates. Follow us and get updated :D\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fwww.instagram.com\u002Fpequimecanico\u002F\"\u003EInstagram\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fwww.facebook.com\u002FNucleoPMec\"\u003EFacebook\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n",readingTime:c,title:"IEEE VSSS Team",slug:"2018-10-10-ieee-vsss-team",date:"2018-10-10",urls:[{cta:a,url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002FPY-VSSS-INF"},{cta:"Team Description Paper",url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002FPY-VSSS-INF\u002Fblob\u002Fmaster\u002Fdocs\u002FTDP%20VSSS%20INF%202018.pdf"}],type:"Robotics",tags:[b,"robotics","leadership"],image:"\u002Fimg\u002Fvsss.png",description:"A stack consisting of image processing, computer vision, team coordination, navigation, control and communication software to compete in the 2018's Latin-American Robotics Competition for the Pequi Mecânico UFG - INF's team."},{html:"\u003Cp\u003EIn a world overrun by zombies, you must survive as long as possible and defeat different bosses while unlocking weapons, upgrades, equipment, characters, maps and much more. Reviving the classics of the &#39;80s and &#39;90s, Die Zombit is a retro wave top-down shooting game with an amazing soundtrack and addictive gameplay that guarantees many hours of fun. Check out its trailer:\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=sO7FSZ3TJns\" target=\"_blank\"\u003E\n    \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Funity-zombit\u002Fraw\u002Fmaster\u002FImages\u002Fzombit_miniature.jpg\" width=\"480\"\u002F\u003E\n\u003C\u002Fa\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Cbr\u002F\u003E\n\n\u003Cp\u003EI made this game during my first year in the Computer Science course. I believe the project could be significantly improved using better design patterns, clearer abstractions and algorithmic complexity in mind. Yet, it is a fun game that you can \u003Ca href=\"https:\u002F\u002Fplay.google.com\u002Fstore\u002Fapps\u002Fdetails?id=com.elitgames.zombit\"\u003Edownload\u003C\u002Fa\u003E (an older version) in Play Store.\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Funity-zombit\u002Fraw\u002Fmaster\u002FImages\u002F3.png\" width=\"230\" height=\"180\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Funity-zombit\u002Fraw\u002Fmaster\u002FImages\u002F2.png\" width=\"230\" height=\"180\"\u003E \u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Funity-zombit\u002Fraw\u002Fmaster\u002FImages\u002F1.png\" width=\"230\" height=\"180\"\u003E\n\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\n\n\u003Ch2 id=\"requirements-and-instructions\"\u003ERequirements and Instructions\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Install Unity3D (tested for v2019.3)\u003C\u002Fli\u003E\n\u003Cli\u003E  Open the project folder\u003C\u002Fli\u003E\n\u003Cli\u003E  Hit Play and have fun!\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"to-dos-and-known-bugs\"\u003ETO-DOs and Known Bugs\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  [ ] Fix joystick and touchscreen support\u003C\u002Fli\u003E\n\u003Cli\u003E  [ ] Fix pause menu UI\u003C\u002Fli\u003E\n\u003Cli\u003E  [ ] Fix end game UI\u003C\u002Fli\u003E\n\u003Cli\u003E  [ ] Add multiplayer support\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"credits\"\u003ECredits\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003ESoundtracks by\u003Cul\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fsoundcloud.com\u002Fbossfightswe\"\u003EBossfight\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fsoundcloud.com\u002Fultrasyd\"\u003EUltrasyd\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fsoundcloud.com\u002Fdunderpatrullen\"\u003EDunderpatrullen\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  \u003Ca href=\"https:\u002F\u002Fsoundcloud.com\u002Fdetiouss\"\u003EDetious\u003C\u002Fa\u003E &amp; \u003Ca href=\"https:\u002F\u002Fsoundcloud.com\u002Flockyn\"\u003ELockyn\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n",readingTime:c,title:"Die Zombit",slug:"2015-06-10-die-zombit",date:"2015-06-10",urls:[{cta:a,url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Funity-zombit"},{cta:"Store",url:"https:\u002F\u002Fplay.google.com\u002Fstore\u002Fapps\u002Fdetails?id=com.elitgames.zombit"}],type:e,tags:[b,d,f],image:"\u002Fimg\u002Fzombit.png",description:"Reviving the classics of the 80's and 90's, Die Zombit is a retrowave top-down shooting game that has a striking soundtrack and an addictive gameplay which guarantee many hours of fun."}]}}("Code","project","2 min read","game","Game","indie"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.ddc03fc7.js"}catch(e){main="/client/legacy/client.551a0101.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@2.0.4.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> <link href=client/client-f256ac86.css rel=stylesheet><link href=client/HorizontalNamePhoto-83c2ef81.css rel=stylesheet><link href=client/PostListItem-a56df87b.css rel=stylesheet><link href=client/index-ca4a0f66.css rel=stylesheet> <title>Blog</title> <link href=/client/client.ddc03fc7.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/client-f256ac86.css rel=preload as=style><link href=/client/index.fe303e53.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/HorizontalNamePhoto.c701b33c.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/PostListItem.4dc4052c.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/inject_styles.5607aec6.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/HorizontalNamePhoto-83c2ef81.css rel=preload as=style><link href=/client/PostListItem-a56df87b.css rel=preload as=style><link href=/client/index-ca4a0f66.css rel=preload as=style></head> <body> <div id=sapper> <div class="mt-5 cover-container d-flex flex-column mx-auto p-3 svelte-e1wq04 w-100"><main class="mb-5 cover svelte-e1wq04"> <a href=/ class=back rel=prefetch>« home</a> <div class="mb-5 mt-5 pb-3 text-center"><h1 class=mt-2>Blog</h1></div> <div><div class="svelte-1povu5z mb-3 post-item row"><div class=col-md-8><h3 class=svelte-1povu5z> <a href=blog/2021-03-10-cellular-automata class=svelte-1povu5z rel=prefetch>Cellular Automata Framework</a></h3> <small class="svelte-1povu5z text-muted">Project · March 2021</small> <p class="indicate_blank item-description">A <a href=https://en.wikipedia.org/wiki/Cellular_automaton target=_blank>Cellular Automata</a> program built with C++, CUDA and OpenGL. The main objective of this project is to allow scaling up to a reasonably large number of cells while maintaining the code legibility and allowing for further customizations. <a href=blog/2021-03-10-cellular-automata class=svelte-1povu5z rel=prefetch target=_blank>Read more </a></div> <div class=col-md-4><a href=blog/2021-03-10-cellular-automata class=svelte-1povu5z rel=prefetch><img alt="Cellular Automata Framework" class=svelte-1povu5z src=https://github.com/bryanoliveira/cellular-automata/raw/master/docs/100x100.gif></a></div> </div><div class="svelte-1povu5z mb-3 post-item row"><div class=col-md-8><h3 class=svelte-1povu5z> <a href=blog/2019-12-10-intrinsic-motivation class=svelte-1povu5z rel=prefetch>Intrinsic motivation for robotic manipulation learning with sparse rewards</a></h3> <small class="svelte-1povu5z text-muted">Undergraduate Thesis · December 2019</small> <p class="indicate_blank item-description">Intrinsic motivation for robotic manipulation learning with sparse rewards - Study of the impact of curiosity and intrinsic motivation as an exploration strategy for deep reinforcement learning agents on sparse-reward robotic manipulator environments. <a href=blog/2019-12-10-intrinsic-motivation class=svelte-1povu5z rel=prefetch target=_blank>Read more </a></div> <div class=col-md-4><a href=blog/2019-12-10-intrinsic-motivation class=svelte-1povu5z rel=prefetch><img alt="Intrinsic motivation for robotic manipulation learning with sparse rewards" class=svelte-1povu5z src=/img/pick.gif></a></div> </div><div class="svelte-1povu5z mb-3 post-item row"><div class=col-md-8><h3 class=svelte-1povu5z> <a href=blog/2019-11-10-bone-age-regression class=svelte-1povu5z rel=prefetch>Bone Age Regression</a></h3> <small class="svelte-1povu5z text-muted">Deep Learning · November 2019</small> <p class="indicate_blank item-description">This is my code for the <a href=https://www.kaggle.com/c/bone-age-regression>I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice. <a href=blog/2019-11-10-bone-age-regression class=svelte-1povu5z rel=prefetch target=_blank>Read more </a></div> <div class=col-md-4><a href=blog/2019-11-10-bone-age-regression class=svelte-1povu5z rel=prefetch><img alt="Bone Age Regression" class=svelte-1povu5z src=/img/bone.png></a></div> </div><div class="svelte-1povu5z mb-3 post-item row"><div class=col-md-8><h3 class=svelte-1povu5z> <a href=blog/2019-01-10-quack class=svelte-1povu5z rel=prefetch>Quack</a></h3> <small class="svelte-1povu5z text-muted">Game · January 2019</small> <p class="indicate_blank item-description">Quack is a Unity3D game made for the Global Game Jam 2019 themed "What home means to you?". The game consists of a happy chicken that wants to build a new home for its children. You have to collect sticks and group them on top of the main tree to make a lovely nest. This game was developed within 12 hours. <a href=blog/2019-01-10-quack class=svelte-1povu5z rel=prefetch target=_blank>Read more </a></div> <div class=col-md-4><a href=blog/2019-01-10-quack class=svelte-1povu5z rel=prefetch><img alt=Quack class=svelte-1povu5z src=/img/quack.png></a></div> </div><div class="svelte-1povu5z mb-3 post-item row"><div class=col-md-8><h3 class=svelte-1povu5z> <a href=blog/2018-12-10-rigid-body-physics class=svelte-1povu5z rel=prefetch>Rigid Body Physics Simulator</a></h3> <small class="svelte-1povu5z text-muted">Rendering · December 2018</small> <p class="indicate_blank item-description">3D Rigid Body Physics simulator using only Processing's point() and line functions. Uses Digital Differential Analyzer (DDA) to render lines between two points, Scan Line to render polygons, normal calculation to determine faces to render in 3D space and Newtonian physics. Written in Java. <a href=blog/2018-12-10-rigid-body-physics class=svelte-1povu5z rel=prefetch target=_blank>Read more </a></div> <div class=col-md-4><a href=blog/2018-12-10-rigid-body-physics class=svelte-1povu5z rel=prefetch><img alt="Rigid Body Physics Simulator" class=svelte-1povu5z src=/img/rigidbody_physics.gif></a></div> </div><div class="svelte-1povu5z mb-3 post-item row"><div class=col-md-8><h3 class=svelte-1povu5z> <a href=blog/2018-10-10-ieee-vsss-team class=svelte-1povu5z rel=prefetch>IEEE VSSS Team</a></h3> <small class="svelte-1povu5z text-muted">Robotics · October 2018</small> <p class="indicate_blank item-description">A stack consisting of image processing, computer vision, team coordination, navigation, control and communication software to compete in the 2018's Latin-American Robotics Competition for the Pequi Mecânico UFG - INF's team. <a href=blog/2018-10-10-ieee-vsss-team class=svelte-1povu5z rel=prefetch target=_blank>Read more </a></div> <div class=col-md-4><a href=blog/2018-10-10-ieee-vsss-team class=svelte-1povu5z rel=prefetch><img alt="IEEE VSSS Team" class=svelte-1povu5z src=/img/vsss.png></a></div> </div><div class="svelte-1povu5z mb-3 post-item row"><div class=col-md-8><h3 class=svelte-1povu5z> <a href=blog/2015-06-10-die-zombit class=svelte-1povu5z rel=prefetch>Die Zombit</a></h3> <small class="svelte-1povu5z text-muted">Game · June 2015</small> <p class="indicate_blank item-description">Reviving the classics of the 80's and 90's, Die Zombit is a retrowave top-down shooting game that has a striking soundtrack and an addictive gameplay which guarantee many hours of fun. <a href=blog/2015-06-10-die-zombit class=svelte-1povu5z rel=prefetch target=_blank>Read more </a></div> <div class=col-md-4><a href=blog/2015-06-10-die-zombit class=svelte-1povu5z rel=prefetch><img alt="Die Zombit" class=svelte-1povu5z src=/img/zombit.png></a></div> </div></div> <hr> <footer class="indicate_blank text-center"><small class="text-muted horizontal-name-photo svelte-1sdunwv"><a href=. class=no-underline><img alt="Bryan Oliveira" class=svelte-1sdunwv src=/img/me.jpg id=img-me> <h2 class=svelte-1sdunwv>Bryan Oliveira</h2></a> </small></footer></main> </div></div> 