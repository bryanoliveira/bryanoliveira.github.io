<!DOCTYPE html> <html lang=en> <head> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169339523-1"></script> <script> window.dataLayer = window.dataLayer || []
            function gtag() {
                dataLayer.push(arguments)
            }
            gtag('js', new Date())

            gtag('config', 'UA-169339523-1') </script> <meta charset=utf-8> <meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"> <meta name=author content="Bryan Oliveira"> <meta name=theme-color content=#FFFFFF> <title>Bryan Oliveira</title> <base href=/ > <link href=/manifest.json rel=manifest crossorigin=use-credentials> <link href=/img/icon.png rel=icon type=image/png> <link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400&display=swap" rel=stylesheet> <link href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-dark-reasonable.min.css rel=stylesheet> <link href=/css/fonts.css rel=stylesheet> <link href=/css/bootstrap.css rel=stylesheet> <link href=/css/global.css rel=stylesheet> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,(function(a){return {post:{html:"\u003Cp\u003EThis is my code for the \u003Ca href=\"https:\u002F\u002Fwww.kaggle.com\u002Fc\u002Fbone-age-regression\"\u003EI2A2 Bone Age Regression competition\u003C\u002Fa\u003E. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.\u003C\u002Fp\u003E\n\u003Cp\u003EThis competition was inspired by \u003Ca href=\"https:\u002F\u002Fwww.kaggle.com\u002Fkmader\u002Frsna-bone-age\"\u003ERSNA&#39;s Bone Age challenge\u003C\u002Fa\u003E, in which given hand X-ray images, the model should predict the patient&#39;s bone age.\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression\u002Fraw\u002Fmaster\u002Fdocs\u002Fex1.png\" width=\"230\" height=\"320\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression\u002Fraw\u002Fmaster\u002Fdocs\u002Fex2.png\" width=\"230\" height=\"320\"\u003E\n\u003Cimg src=\"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression\u002Fraw\u002Fmaster\u002Fdocs\u002Fex3.png\" width=\"230\" height=\"320\"\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003EX-ray images provided in the competition&#39;s dataset.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Cp\u003EMy final solution used a \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1512.03385\"\u003EResNet50\u003C\u002Fa\u003E architecture, a \u003Ca href=\"https:\u002F\u002Farxiv.org\u002Fabs\u002F1908.03265\"\u003ERectified Adam\u003C\u002Fa\u003E optimizer and geometric data augmentations. This model achieved a Mean Average Error of 13.2 after 20 epochs of training, which I believe could be improved given more training time and a better preprocessing pipeline (e.g. using object detection to segment the hands and normalizing hand rotation). Unfortunately, I didn&#39;t save all the hyperparameters I experimented with (neither their results), but you&#39;ll find the ones I used for my last submission in the code.\u003C\u002Fp\u003E\n\u003Cp\u003EI used \u003Ca href=\"https:\u002F\u002Fwww.tensorflow.org\u002Ftensorboard\"\u003Etensorboard\u003C\u002Fa\u003E to log the training curves and \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Ftqdm\u002Ftqdm\"\u003Etqdm\u003C\u002Fa\u003E to track progress. I also used \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Ffcm-notifier\"\u003EFCMNotifier\u003C\u002Fa\u003E, a tool I made to send logs as notifications to my phone.\u003C\u002Fp\u003E\n\u003Ch2 id=\"requirements\"\u003ERequirements\u003C\u002Fh2\u003E\n\u003Cp\u003ESee \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fbryanlincoln\u002Fbone-age-regression\u002Fblob\u002Fmaster\u002Frequirements.txt\"\u003Erequirements.txt\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Ch2 id=\"usage\"\u003EUsage\u003C\u002Fh2\u003E\n\u003Cul\u003E\n\u003Cli\u003E  Download the requirements with \u003Ccode\u003Epip install -r requirements.txt\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  Download the dataset and sample submission with \u003Ccode\u003Esh download_data.sh\u003C\u002Fcode\u003E. You may need to log in with your Kaggle account in order to do it.\u003C\u002Fli\u003E\n\u003Cli\u003E  Train the ResNet50 model with \u003Ccode\u003Epython boneage.py\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E  Try different models and hyperparameters by editing the training script or use the \u003Ccode\u003Eboneage.ipynb\u003C\u002Fcode\u003E notebook to do it interactively.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch2 id=\"credits\"\u003ECredits\u003C\u002Fh2\u003E\n\u003Cp\u003EI used the vision models already \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fpytorch\u002Fvision\u002Ftree\u002Fmaster\u002Ftorchvision\u002Fmodels\"\u003Eimplemented in torchvision\u003C\u002Fa\u003E with slight changes. You can try other torchvision models by adding the \u003Ccode\u003Ein_channels\u003C\u002Fcode\u003E parameter to generalize the number of input channels since torchvision models work with RGB images.\u003C\u002Fp\u003E\n",readingTime:"2 min read",title:"Bone Age Regression",slug:a,date:"2019-11-10",urls:[{cta:"Code",url:"https:\u002F\u002Fgithub.com\u002Fbryanoliveira\u002Fbone-age-regression"}],type:"Deep Learning",tags:["project","ai","deeplearning"],image:"\u002Fimg\u002Fbone.png",description:"This is my code for the \u003Ca href=\"https:\u002F\u002Fwww.kaggle.com\u002Fc\u002Fbone-age-regression\"\u003EI2A2 Bone Age Regression competition\u003C\u002Fa\u003E. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice."},slug:a}}("2019-11-10-bone-age-regression"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.f98bea0b.js"}catch(e){main="/client/legacy/client.009c03eb.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@2.0.4.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> <link href=client/client-f256ac86.css rel=stylesheet><link href=client/HorizontalNamePhoto-83c2ef81.css rel=stylesheet><link href=client/[slug]-0f4d1406.css rel=stylesheet> <title>Bone Age Regression</title><link href=https://bryanoliveira.github.io/blog/2019-11-10-bone-age-regression rel=canonical data-svelte=svelte-pdj2vk><meta data-svelte=svelte-pdj2vk content=article property=og:type><meta data-svelte=svelte-pdj2vk content="Bone Age Regression" property=og:title><meta data-svelte=svelte-pdj2vk name=Description content='This is my code for the <a href="https://www.kaggle.com/c/bone-age-regression">I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.'><meta data-svelte=svelte-pdj2vk content='This is my code for the <a href="https://www.kaggle.com/c/bone-age-regression">I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.' property=og:description><meta data-svelte=svelte-pdj2vk content=/img/bone.png property=og:image><meta data-svelte=svelte-pdj2vk name=twitter:card content=summary_large_image><meta data-svelte=svelte-pdj2vk name=twitter:domain value=bryanoliveira.github.io><meta data-svelte=svelte-pdj2vk name=twitter:creator value=bryanoliveira_><meta data-svelte=svelte-pdj2vk name=twitter:title value="Bone Age Regression"><meta data-svelte=svelte-pdj2vk name=twitter:description content='This is my code for the <a href="https://www.kaggle.com/c/bone-age-regression">I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.'><meta data-svelte=svelte-pdj2vk name=twitter:image content=/img/bone.png><meta data-svelte=svelte-pdj2vk name=twitter:label1 value="Published on"><meta data-svelte=svelte-pdj2vk name=twitter:data1 value="Nov 9, 2019"><meta data-svelte=svelte-pdj2vk name=twitter:label2 value="Reading Time"><meta data-svelte=svelte-pdj2vk name=twitter:data2 value="2 min read"> <link href=/client/client.f98bea0b.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/client-f256ac86.css rel=preload as=style><link href=/client/[slug].a595f129.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/HorizontalNamePhoto.d65d1d60.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/inject_styles.5607aec6.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/HorizontalNamePhoto-83c2ef81.css rel=preload as=style><link href=/client/[slug]-0f4d1406.css rel=preload as=style></head> <body> <div id=sapper> <div class="mt-5 cover-container d-flex flex-column mx-auto p-3 svelte-e1wq04 w-100"><main class="cover mb-5 svelte-e1wq04"> <a href=/blog class=back rel=prefetch>« posts</a> <div class="mb-5 mt-5 text-center"><h1>Bone Age Regression</h1> <div class="text-muted mt-4">Deep Learning · <span title=11/9/2019>November 2019</span> · 2 min read</div></div> <div class=row><div class=col-md-8><p>This is my code for the <a href=https://www.kaggle.com/c/bone-age-regression>I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.</p> <div class=mb-3><a href=https://github.com/bryanoliveira/bone-age-regression class="no-underline btn btn-secondary btn-sm mr-1" target=_blank>Code ⧉ </a></div></div> <div class=col-md-4><img src=/img/bone.png alt="Bone Age Regression" class="cover svelte-17yxpyn"></div></div> <hr> <div class="svelte-17yxpyn post"><p>This is my code for the <a href=https://www.kaggle.com/c/bone-age-regression>I2A2 Bone Age Regression competition</a>. I learned a lot by building this pipeline from scratch and experimenting with different model architectures and optimizers. This was my first end-to-end image regression model, and it was very nice seeing my theoretical knowledge work in practice.</p> <p>This competition was inspired by <a href=https://www.kaggle.com/kmader/rsna-bone-age>RSNA's Bone Age challenge</a>, in which given hand X-ray images, the model should predict the patient's bone age.</p> <div align=center> <img src=https://github.com/bryanoliveira/bone-age-regression/raw/master/docs/ex1.png height=320 width=230> <img src=https://github.com/bryanoliveira/bone-age-regression/raw/master/docs/ex2.png height=320 width=230> <img src=https://github.com/bryanoliveira/bone-age-regression/raw/master/docs/ex3.png height=320 width=230> </div> <blockquote> <p>X-ray images provided in the competition's dataset.</p> </blockquote> <p>My final solution used a <a href=https://arxiv.org/abs/1512.03385>ResNet50</a> architecture, a <a href=https://arxiv.org/abs/1908.03265>Rectified Adam</a> optimizer and geometric data augmentations. This model achieved a Mean Average Error of 13.2 after 20 epochs of training, which I believe could be improved given more training time and a better preprocessing pipeline (e.g. using object detection to segment the hands and normalizing hand rotation). Unfortunately, I didn't save all the hyperparameters I experimented with (neither their results), but you'll find the ones I used for my last submission in the code.</p> <p>I used <a href=https://www.tensorflow.org/tensorboard>tensorboard</a> to log the training curves and <a href=https://github.com/tqdm/tqdm>tqdm</a> to track progress. I also used <a href=https://github.com/bryanlincoln/fcm-notifier>FCMNotifier</a>, a tool I made to send logs as notifications to my phone.</p> <h2 id=requirements>Requirements</h2> <p>See <a href=https://github.com/bryanlincoln/bone-age-regression/blob/master/requirements.txt>requirements.txt</a>.</p> <h2 id=usage>Usage</h2> <ul> <li> Download the requirements with <code>pip install -r requirements.txt</code></li> <li> Download the dataset and sample submission with <code>sh download_data.sh</code>. You may need to log in with your Kaggle account in order to do it.</li> <li> Train the ResNet50 model with <code>python boneage.py</code></li> <li> Try different models and hyperparameters by editing the training script or use the <code>boneage.ipynb</code> notebook to do it interactively.</li> </ul> <h2 id=credits>Credits</h2> <p>I used the vision models already <a href=https://github.com/pytorch/vision/tree/master/torchvision/models>implemented in torchvision</a> with slight changes. You can try other torchvision models by adding the <code>in_channels</code> parameter to generalize the number of input channels since torchvision models work with RGB images.</p> </div> <hr> <footer class="indicate_blank text-center"><small class="svelte-1sdunwv horizontal-name-photo text-muted"><a href=. class=no-underline><img src=/img/me.jpg alt="Bryan Oliveira" class=svelte-1sdunwv id=img-me> <h2 class=svelte-1sdunwv>Bryan Oliveira</h2></a> </small> </footer></main> </div></div> 