<!DOCTYPE html> <html lang=en> <head> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169339523-1"></script> <script> window.dataLayer = window.dataLayer || []
            function gtag() {
                dataLayer.push(arguments)
            }
            gtag('js', new Date())

            gtag('config', 'UA-169339523-1') </script> <meta charset=utf-8> <meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"> <meta name=author content="Bryan Oliveira"> <meta name=theme-color content=#FFFFFF> <title>Bryan Oliveira</title> <base href=/ > <link href=/manifest.json rel=manifest crossorigin=use-credentials> <link href=/img/icon.png rel=icon type=image/png> <link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400&display=swap" rel=stylesheet> <link href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-dark-reasonable.min.css rel=stylesheet> <link href=/css/fonts.css rel=stylesheet> <link href=/css/bootstrap.css rel=stylesheet> <link href=/css/global.css rel=stylesheet> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,(function(a){return {post:{html:"\u003Ch2 id=\"abstract\"\u003EAbstract\u003C\u002Fh2\u003E\n\u003Cp\u003ELarge language models excel at following explicit instructions, but they often struggle with ambiguous or incomplete user requests, defaulting to verbose, generic responses instead of seeking clarification. We introduce InfoQuest, a multi-turn chat benchmark designed to evaluate how dialogue agents handle hidden context in open-ended user requests. This benchmark presents intentionally ambiguous scenarios that require models to engage in information-seeking dialogue by asking clarifying questions before providing appropriate responses. Our evaluation of both open and closed models reveals that, while proprietary models generally perform better, all current assistants struggle to gather critical information effectively. They often require multiple turns to infer user intent and frequently default to generic responses without proper clarification. We provide a systematic methodology for generating diverse scenarios and evaluating models&#39; information-seeking capabilities, which can be leveraged to automatically generate data for self-improvement. We also offer insights into the current limitations of language models in handling ambiguous requests through multi-turn interactions.\u003C\u002Fp\u003E\n\u003Cdiv align=\"center\"\u003E\n    \u003Cimg class=\"text-img mw-100\" src=\"\u002Fimg\u002Finfoquest_diagram.png\"\u003E\n\u003C\u002Fdiv\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003E\u003Cb\u003EInfoQuest&#39;s three-stage benchmark construction process.\u003C\u002Fb\u003E Left: initial state generation by selecting personas and creating ambiguous messages. Center: user setting with persona traits, goals, obstacles and constraints. Right: generation of a checklist to evaluate information gathering.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Chr\u003E\n\u003Cp\u003EPresented at the Workshop on Scaling Self-Improving Foundation Models without Human Supervision at the 13th International Conference on Learning Representations (ICLR).\u003C\u002Fp\u003E\n",readingTime:"2 min read",title:"InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context",slug:a,date:"2025-03-08",urls:[{cta:"Paper",url:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2502.12257"},{cta:"Data",url:"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Fbryanlincoln\u002Finfoquest"}],type:"Workshop on SSI-FM @ ICLR 2025",tags:["research","featured"],image:"\u002Fimg\u002Finfoquest_cover.png",description:"A benchmark for evaluating how LLMs handle ambiguous open-ended requests through dialogue, revealing that current models struggle to ask effective clarifying questions."},slug:a}}("2025-03-infoquest"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.d93174ea.js"}catch(e){main="/client/legacy/client.ceb7b0a2.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@2.0.4.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> <link href=client/client-f256ac86.css rel=stylesheet><link href=client/HorizontalNamePhoto-83c2ef81.css rel=stylesheet><link href=client/[slug]-a70e5dcf.css rel=stylesheet> <title>InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context</title><link href=https://bryanoliveira.github.io/blog/2025-03-infoquest rel=canonical data-svelte=svelte-17660c7><meta data-svelte=svelte-17660c7 name=Description content="A benchmark for evaluating how LLMs handle ambiguous open-ended requests through dialogue, revealing that current models struggle to ask effective clarifying questions."><meta data-svelte=svelte-17660c7 content=article property=og:type><meta data-svelte=svelte-17660c7 content="InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context" property=og:title><meta data-svelte=svelte-17660c7 content=https://bryanoliveira.github.io/blog/2025-03-infoquest property=og:url><meta data-svelte=svelte-17660c7 content="A benchmark for evaluating how LLMs handle ambiguous open-ended requests through dialogue, revealing that current models struggle to ask effective clarifying questions." property=og:description><meta data-svelte=svelte-17660c7 content=/img/infoquest_cover.png property=og:image><meta data-svelte=svelte-17660c7 name=image content=/img/infoquest_cover.png><meta data-svelte=svelte-17660c7 name=twitter:card content=summary_large_image><meta data-svelte=svelte-17660c7 name=twitter:domain value=bryanoliveira.github.io><meta data-svelte=svelte-17660c7 name=twitter:creator value=bryanoliveira_><meta data-svelte=svelte-17660c7 name=twitter:title value="InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context"><meta data-svelte=svelte-17660c7 name=twitter:description content="A benchmark for evaluating how LLMs handle ambiguous open-ended requests through dialogue, revealing that current models struggle to ask effective clarifying questions."><meta data-svelte=svelte-17660c7 name=twitter:image content=/img/infoquest_cover.png><meta data-svelte=svelte-17660c7 name=twitter:label1 value="Published on"><meta data-svelte=svelte-17660c7 name=twitter:data1 value="Mar 8, 2025"><meta data-svelte=svelte-17660c7 name=twitter:label2 value="Reading Time"><meta data-svelte=svelte-17660c7 name=twitter:data2 value="2 min read"> <link href=/client/client.d93174ea.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/client-f256ac86.css rel=preload as=style><link href=/client/[slug].ea8b2f91.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/HorizontalNamePhoto.1a9df1d7.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/inject_styles.5607aec6.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/HorizontalNamePhoto-83c2ef81.css rel=preload as=style><link href=/client/[slug]-a70e5dcf.css rel=preload as=style></head> <body> <div id=sapper> <div class="svelte-e1wq04 cover-container d-flex flex-column mt-5 mx-auto p-3 w-100"><main class="mb-5 cover svelte-e1wq04"> <a class=back href=/blog rel=prefetch>« posts</a> <div class="text-center mb-5 mt-5"><h1>InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context</h1> <div class="text-muted mt-4">Workshop on SSI-FM @ ICLR 2025 · <span title=3/8/2025>March 2025</span> · 2 min read</div></div> <div class=row><div class=col-md-8><p>A benchmark for evaluating how LLMs handle ambiguous open-ended requests through dialogue, revealing that current models struggle to ask effective clarifying questions.</p> <div class="text-center mb-3 text-md-left"><a class="no-underline btn btn-secondary btn-sm mb-1 mr-1" href=https://arxiv.org/abs/2502.12257 target=_blank>Paper ⧉ </a><a class="no-underline btn btn-secondary btn-sm mb-1 mr-1" href=https://huggingface.co/datasets/bryanlincoln/infoquest target=_blank>Data ⧉ </a></div></div> <div class=col-md-4><img class="svelte-qbrnkn cover-img" src=/img/infoquest_cover.png alt="InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context"></div></div> <hr> <div class="svelte-qbrnkn post"><h2 id=abstract>Abstract</h2> <p>Large language models excel at following explicit instructions, but they often struggle with ambiguous or incomplete user requests, defaulting to verbose, generic responses instead of seeking clarification. We introduce InfoQuest, a multi-turn chat benchmark designed to evaluate how dialogue agents handle hidden context in open-ended user requests. This benchmark presents intentionally ambiguous scenarios that require models to engage in information-seeking dialogue by asking clarifying questions before providing appropriate responses. Our evaluation of both open and closed models reveals that, while proprietary models generally perform better, all current assistants struggle to gather critical information effectively. They often require multiple turns to infer user intent and frequently default to generic responses without proper clarification. We provide a systematic methodology for generating diverse scenarios and evaluating models' information-seeking capabilities, which can be leveraged to automatically generate data for self-improvement. We also offer insights into the current limitations of language models in handling ambiguous requests through multi-turn interactions.</p> <div align=center> <img class="mw-100 text-img" src=/img/infoquest_diagram.png> </div> <blockquote> <p><b>InfoQuest's three-stage benchmark construction process.</b> Left: initial state generation by selecting personas and creating ambiguous messages. Center: user setting with persona traits, goals, obstacles and constraints. Right: generation of a checklist to evaluate information gathering.</p> </blockquote> <hr> <p>Presented at the Workshop on Scaling Self-Improving Foundation Models without Human Supervision at the 13th International Conference on Learning Representations (ICLR).</p> </div> <hr> <footer class="text-center indicate_blank"><small class="svelte-1sdunwv horizontal-name-photo text-muted"><a class=no-underline href=.><img class=svelte-1sdunwv src=/img/me.jpg alt="Bryan Oliveira" id=img-me> <h2 class=svelte-1sdunwv>Bryan Oliveira</h2></a> </small> </footer></main> </div></div> 